\section{Transport Layer}
\subsection{Transport Layer Services}
Some terminology:
\begin{itemize}
	\item \textbf{Program}: An executable file containing a set of instructions written to perform a specific job (usually stored on a disk)
	\item \textbf{Process}: An executing \textit{instance} of a program that resides on the primary memory. Several processes can be related to the same program at the same time
	\item \textbf{Thread}\footnote{\textbf{Thread} of execution is the smallest sequence of programmed instructions that can be managed independently by a scheduler, which is typically a part of the operating system.}: The smallest executable unit of a process
\end{itemize}

\subsubsection{Transport Layer Function}
\begin{itemize}
	\item Provides \textbf{logical communication between processes}
	\item The layer relies on and enhances services from the network layer\footnote{The network layer provides logical communication between \textbf{hosts}}
	\item Sending Side
	\begin{itemize}
		\item Applies \textbf{fragmentation} to application messages
		\item Passes segments\footnote{We see terms like \textit{frame}, \textit{datagram}, \textit{packet}, \textit{segment} when we study computer networks. They are similar, but we use layer-specific terms to represent the information unit in that layer. In the transport layer, we use the term \textbf{segment}.} to network layer
	\end{itemize}
	\item Receiving Side
	\begin{itemize}
		\item \textbf{Reassembles} segments into messages
		\item Passes the assembled message to the application layer
	\end{itemize}
\end{itemize}

\subsubsection{TCP and UDP}
\begin{itemize}
	\item \textbf{Transmission Control Protocol} (TCP)\footnote{Refer to 2.1.6.}
	\begin{itemize}
		\item \textbf{Reliable}, \textbf{in-order}\footnote{This doesn't mean that the order of sent messages is always preserved when receiving. (physically) In the application layer's point of view, it just \textit{seems} like it's received in the same order.} delivery
		\item \textbf{Connection oriented} service: connection setup, error control, flow control, congestion control
	\end{itemize}
	\item \textbf{User Datagram Protocol} (UDP)
	\begin{itemize}
		\item Unreliable, unordered delivery
		\item Connection-less service: faster than TCP
	\end{itemize}
\end{itemize}

\subsection{Multiplexing and Socket}
\subsubsection{Multiplexing and Demultiplexing}
\begin{itemize}
	\item This is the most basic role of the transport layer
	\item \textbf{Multiplexing} at sender: the sender sends data from its own multiple applications through network
	\item Data from multiple services are sent through a single shared channel
	\item \textbf{Demultiplexing} at receiver: the receiver delivers data packets to their appropriate receivers among its own multiple applications
	\item \textbf{Port numbers} are used for demultiplexing
	\begin{itemize}
		\item Different applications are assigned to different port numbers
		\item Transport layer segments have fields for source/destination port numbers in common
		\item Used to differentiate segments
	\end{itemize}
	\item Note that for connection oriented protocols (like TCP), the source IP and port are also used to differentiate each connection\footnote{Multiple applications can listen on the same port.}
	\item But how does the sender know the destination port on the receiver?
\end{itemize}

\subsubsection{Sockets}
\begin{itemize}
	\item API between application layer and transport layer
	\item Processes send/receive messages to/from its \textbf{socket}
	\item Analogous to door
	\begin{itemize}
		\item Sender passes message through the door
		\item Sender relies on transport infrastructure on other side of the door to deliver message to socket at the receiving process
	\end{itemize}
	\item The \textit{socket} is provided as the form of APIs by the operating system
\end{itemize}

\subsection{User Datagram Protocol}
\begin{itemize}
	\item Only provides the basic functions (multiplexing)
	\item \textbf{Connection-less} service
	\begin{itemize}
		\item Each UDP segment is handled independently of others
		\item \textit{Unreliable}: UDP segments may be lost or delivered out of order to app
	\end{itemize}
	\item But since UDP is fast, it is used for streaming multimedia applications, DNS, and SNMP
	\item For reliable transfer over UDP, the application must add that function (such as application specific error recovery)
	\item \textbf{UDP segment header}: Source port (16 bits), Destination port (16 bits), length, checksum, payload
	\item \textbf{Advantages}
	\begin{itemize}
		\item No connection establishment (no delay)
		\item Simple: No connection state at sender/receiver
		\item Small header size\footnote{Compare this to TCP headers.}
		\item No congestion control: UDP can blast away as fast as desired
	\end{itemize}
	\item \textbf{UDP Checksum}
	\begin{itemize}
		\item Detects transmission errors
		\item UDP doesn't have to provide reliable connections, but this checksum can be used to provide additional features elsewhere
		\item Sender creates a 16 bit integer checksum code of segment contents including the header
		\item The receiver will compute the checksum of the received message, and checks if the computed value is equal to the received value
	\end{itemize}
\end{itemize}

\subsubsection{Checksum Method}
\begin{itemize}
	\item Checksum is the 16-bit one's complement of the one's complement sum of a pseudo header of information from the IP header, the UDP header, and the data, padded with zero octets at the end (if necessary) to make a multiple of two octets.\footnote{RFC 768}
\end{itemize}

\subsection{Reliable Data Transfer Principles}
\subsubsection{Principles of Reliable Data Transfer}
\begin{itemize}
	\item Service abstraction (provided to the upper-layer) through a reliable channel
	\item \textit{Service model of TCP}: No corruption and no loss of data, delivered in the order in which they were sent
	\item The lower layers of the network (below transport layer) is unreliable, but the TCP protocol in the transport layer will pre-process any existing errors and pass them onto the receiver.
\end{itemize}

\subsubsection{Error Types and Solution}
\begin{itemize}
	\item \textbf{Bit Error}
	\begin{itemize}
		\item Some of the bits are changed
		\item This can be checked by comparing the checksum in every segment
		\item If the receiver successfully received the packet, \textbf{ACK}(acknowledgment) message is sent to the sender
	\end{itemize}
	\item \textbf{Packet Loss} (Data or ACK)
	\begin{itemize}
		\item Packet is gone, the receiver doesn't receive the packet
		\item \textit{Timeout} of sender's timer - the sender sends the packet and waits for ACK, but if ACK doesn't arrive, the sender will re-send the packet
		\item But consider the case where the returning ACK is lost - the sender will re-send the packet anyways, but how does the receiver know that this packet is a duplicate or not?
		\item To solve this problem, \textit{packet sequence number} is used
		\item Suppose the receiver received packet $k$, and sent an ACK message. If packet $k$ arrives again, the receiver will know that this packet was re-sent
		\item Also, for transmitting large data, the data will be segmented and labeled with a packet sequence number. Then when the receiver receives the data, it will be possible to re-assemble the original data
		\item Packet sequence numbers allow \textit{ordered delivery} and data duplication prevention
	\end{itemize}
\end{itemize}

\subsubsection{Automatic Repeat Request}
\begin{itemize}
	\item For communication error recovery, we need a packet re-transmission method
	\item We use \textbf{ARQ}(Automatic Repeat reQuest)
	\item \textbf{Stop and wait}: sending and checking one segment at a time
	\item \textbf{Pipelining method}: sending and checking multiple segments at a time (\textit{go back} $N$, \textit{selective repeat} method)
\end{itemize}

\paragraph{Stop and Wait}
\begin{itemize}
	\item Sender sends a packet and waits for the receiver's response with ACK
	\item After receiving the ACK message, the sender will send the next packet
	\item If the sender doesn't receive the ACK message, the sender will re-send the previous packet
	\item The receiver responds with ACK if the calculated checksum matches the checksum value in the segment
	\item The length of \textit{timeout} $t$ is the main problem! 
	\item If $t$ is too long, the sender has to \textit{wait} for that amount of time which will slow down the transmission. 
	\item If $t$ is too short, a normal transmission may be thought of as a timeout (premature timeout). This may happen when the network is too busy. The ACK message couldn't arrive on time. This will cause the sender to re-send the same message again (often), which is a waste of network resource
	\item Thus when setting the timeout time, the \textit{round trip time} between the sender and the receiver should be considered
	\item Performance Analysis
	\begin{itemize}
		\item 1 Gbps link, 15 ms propagation delay, 1 kB packet
		$$d_{trans} = \frac{L}{R} = \frac{8000 \text{ bits}}{10^9 \text{ bits/}s} = 8  \mu s $$
		\item \textbf{Utilization}: fraction of time sender busy sending
		$$U = \frac{d_{trans}}{\text{RTT} + d_{trans}} = 0.00027$$
		\item If RTT\footnote{Round trip time} is 30 ms, 1 kB packet is sent every 30 ms, \textit{so 33 kb/s throughput over 1 Gbps link}\footnote{What a waste of resources!}
		\item Usually $d_{trans}$ is very small (fast link), compared to RTT. Thus $U \approx 0$, which means that the time spent in sending the packet is nearly 0\%
		\item Note that the size of ACK message is very small, thus it is ignored here
	\end{itemize}
\end{itemize}

\paragraph{Pipelined Protocols}
\begin{itemize}
	\item \textbf{Pipelining}: multiple packets can be sent and received
	\item Range of sequence numbers must be increased
	\item Buffering is necessary at sender and receiver
	\item Suppose we send $n$ packets in the above example. ($n$-packet pipelining) Then the utilization\footnote{The denominator doesn't change because we measure the time from [the moment that the first packet was sent], to [the time when ACK for the first packet arrived].} would be
	$$U = \frac{n\cdot d_{trans}}{\text{RTT} + d_{trans}} = 0.00027 n$$ 
	which is a lot better. Now we try to increase the value of $n$
\end{itemize}

\paragraph{Go Back $N$}
\begin{itemize}
	\item The sender can have up to $N$ unacknowledged packets in pipeline at once
	\item The receiver only sends \textbf{cumulative ACK} - if the receiver finds an error in packet $k$, then the sender has to re-send packets $k, \dots, n$
	\item The cumulative ACK will mean: ``transmit successful, up to these packets"
	\item The sender has a timer for \textit{oldest} unacknowledged packet, and when timeout occurs, the sender will re-send all unacknowledged packets
\end{itemize}

\paragraph{Selective Repeat}
\begin{itemize}
	\item The sender can have up to $N$ unacknowledged packets in pipeline at once
	\item The receiver sends \textbf{individual ACK} for each packet - if the receiver finds an error in packet $k$, only that packet needs to be re-sent
	\item The sender has a timer for each unacknowledged packet, and when timeout for packet $k$ occurs, only packet $k$ needs to be re-sent
\end{itemize}

\subsubsection{Go Back $N$ - In Detail}
\paragraph{Sender's Perspective}
\begin{itemize}
	\item Packet sequence number is contained in each packet header
	\item A \textbf{window} is defined - the number of consecutive unacknowledged packets allowed
\end{itemize}
\begin{enumerate}
	\item Let the window size be $n$, and suppose we have sent up to $k$ ($k\leq n$) packets.
	\item The receiver will receive the data, and send a cumulative ACK for packet $i$ ($i\leq k$)
	\item Since the cumulative ACK for packet $i$ has arrived, packets $1, \dots, i$ are acknowledged
	\item The timer will be moved to packet $i + 1$ and wait for the next ACK. If the ACK does not arrive in time, packets $i+1, \dots, k$ will be re-sent
\end{enumerate}
\begin{itemize}
	\item Note that $k$ (number of sent packets) can keep changing in the process above, just keep in mind that the acknowledged packet number $i$ should be less than $k$
	\item Furthermore, the window size $n$ is not fixed. Hence the term \textbf{sliding window}
	\item The larger the window size, higher the throughput, but the number of packets to re-send on an error will also increase
	\item The window size should be controlled so that it does not cause network congestion or receiver buffer overflow
\end{itemize}

\paragraph{Receiver's Perspective}
\begin{itemize}
	\item When packet $k$ arrives,
	\begin{itemize}
		\item \textit{If}: Packet $k+1$ arrives shortly\footnote{Depends on the receiver's settings} after packet $k$ has arrived, wait for the next packet
		\item \textit{Else if}: Packet $k+1$ doesn't arrive (due to congestion or other reasons), respond with \textit{cumulative} ACK for packet $k$ and wait for the next packet
		\item \textit{Else}: A packet other than $k+1$ arrives (ex. packet $k+1$ has been lost), discard the packet\footnote{It's going to be re-sent from the sender anyways} and re-send the last sent ACK
	\end{itemize}
	\item The \textit{Else} case is the only problem. The sender would be expecting ACK for packet $k+1$, but the sender will get the ACK for the last successful transmission\footnote{This duplicate ACK will be ignored}
	\item Then packet $k+1$ will cause timeout and the sender will resend the packets from $k+1, \dots$
\end{itemize}

\subsubsection{Selective Repeat - In Detail}
\begin{itemize}
	\item The receiver will buffer the packets, in case some packet is lost - the receiver waits for that packet to be re-sent, and when the receiver gets it, it can pass that information to the application layer\footnote{Recall that transport layers had to re-assemble the packets before passing them to the application layer, so that it would look like the packets were received in order}
	\item \textbf{Maximum packet sequence number $\geq$ 2 $\times$ window size}
	\item For example, with 4 sequence numbers 0, 1, 2, 3 and window size 3, there could be a case where
	\begin{enumerate}
		\item The sender sent packets 0, 1, 2
		\item \textit{The receiver got those packets and now expects packets 3, 0, 1}
		\item Unfortunately, the ACK for packets 0, 1, 2, do not arrive to the sender
		\item The sender re-sends packets 0, 1, 2 - which are the same packets from step 1
		\item The receiver has no idea that this packet is a re-sent version!
		\item The receiver will accept the re-sent packet 0 as the next packet,   
	\end{enumerate}
	\item The receiver doesn't know what's happening on the senders side. It can only distinguish the packets by the packet sequence number. If the packet sequence number is too small for the window size, data may be corrupted during transmission
\end{itemize}

\subsection{Transmission Control Protocol}
\subsubsection{Overview}
\begin{itemize}
	\item \textit{Point-to-point}: One sender, one receiver
	\item \textbf{Connection Oriented Service}\footnote{How many times has this been repeated...?}
	\begin{itemize}
		\item Reliable transfer, delivery in order
		\item Handshaking initializes sender and receiver state before data exchange
	\end{itemize}
	\item \textbf{Pipelined Transmission}
	\begin{itemize}
		\item Window size is set by TCP congestion and flow control
		\item \textit{Congestion control}: transmission rate is controlled to avoid congestion in network
		\item \textit{Flow control}: sender will not overwhelm the receiver
		\item \textit{MSS}: maximum segment size
	\end{itemize}
	\item \textbf{Full-Duplex Connection}
	\begin{itemize}
		\item In the same connection, data can flow bidirectionally
	\end{itemize}
\end{itemize}

\subsubsection{TCP Segment Structure}
\begin{itemize}
	\item Source/Destination port in the front
	\item Followed by sequence number, acknowledgment number, data offset\footnote{Similar to header length - gives the offset of actual data in the segment}, flags, window size, header/data checksum, urgent pointer
	\item At least 20 bytes, optional fields can follow
\end{itemize}

\paragraph{Sequence and Acknowledgment Number}
\begin{itemize}
	\item \textbf{Sequence number} is the \textit{byte stream number} of the first byte in a segment's data
	\item Large data is fragmented into segments (with size of MSS) when they are sent through the network
	\item The receiver must know the original order of these segments to re-assemble the original data\footnote{Recall that the segments don't actually arrive to the receiver in order, it is the transport layer's job to actually \textit{order} them}
	\item If the first segment has sequence number $n$, the next sequence number will be $n+MSS$.\footnote{The first sequence number isn't necessarily 0, it depends.}
	\item \textbf{Acknowledgment number} is the sequence number of the next segment expected by the receiver, and functions as a \textit{cumulative ACK}
	\item After the receiver gets the first segment, it will put $n + MSS$ (next sequence number) as the acknowledgment number and send it to the sender
	\item The sender will know that the receiver has correctly received data up to that acknowledgment number
	\item There's a \textbf{ACK flag} in the TCP header. If the flag bit is 1, it means that the information in the acknowledgment number is actually meaningful and works as a cumulative ACK
	\item In \textit{go back $N$} or \textit{selective repeat}, the data packet and the ACK packet are the same in TCP
	\item TCP is \textit{full duplex}. The receiver can send its own data to the sender, and also send an ACK number with a single TCP segment. The receiver can make use of the ACK number field in the header to contain the ACK number for the data received from the sender
\end{itemize}

\subsubsection{TCP Reliable Data Transfer}
\begin{itemize}
	\item TCP provides reliable data transfer service on top of IP's \textit{unreliable service}
	\item TCP provides \textbf{pipelined segments} (for throughput/performance), \textbf{cumulative ACKs}, and \textbf{single re-transmission timer}
	\item Using cumulative ACKs and a single transmission timer may seem similar to \textit{go back $N$}, but the difference here is that TCP doesn't throw away packets. TCP will hold on to the received packet in its \textit{receive buffer}\footnote{Its size is limited. But this is possible because the size of TCP's receiving buffer is larger than the congestion window. So the receiver can store the data, provided that it arrives correctly.}
	\item Also this \textit{storage of packets} may seem similar to \textit{selective repeat}\footnote{Kind of a fusion of both methods.}
\end{itemize}

\begin{itemize}
	\item \textbf{TCP Sender}
	\begin{itemize}
		\item When receiving data from application, create a segment with the sequence number and send it, start timer if not already running
		\item When timer expires, re-transmit the segment that caused the timeout and restart timer
		\item When receiving ACK, update acknowledged packet list and start timer if there are still unacknowledged segments
	\end{itemize}
	\item \textbf{TCP Receiver} (When receiving data from sender)
	\begin{itemize}
		\item If it discovers a bit error through checksum, drop the packet
		\item Check the sequence number so that there would be no gaps between sequence numbers. If there isn't any problem, send cumulative ACK
		\item If the packet is duplicated, drop the packet
	\end{itemize}
	\item Note that \textit{handling out of order segments} depends on implementation
\end{itemize}

\paragraph{TCP Timeout Value}
\begin{itemize}
	\item Must be longer than RTT, but this is unknown before connection, and also may change depending on the current network congestion status
	\item In TCP, a \textbf{time out interval} is set by  \textit{estimated RTT} + (safety margin)
	\item The hosts send data and measure the \textit{sample RTT} - the time from segment transmission until ACK arrival
	\item Using the \textit{sample RTT} values, \textit{estimated RTT} is \textit{iteratively} calculated by moving averages, with some weight $\alpha$
	$$t_{n} = (1-\alpha) t_{n-1} + \alpha s_n $$
	where $s_n$ is the $n$-th sample RTT and $t_n$ is the estimated RTT after sampling $n$ times
\end{itemize}

\subsubsection{Fast Re-transmit}
\begin{itemize}
	\item From the above calculations, it turns out that the timeout period is relatively long, so we get a long delay before re-sending the lost packet
	\item Senders often send many segments back-to-back. But if a segment is lost, there will likely be many duplicate ACKs.
	\item For example, suppose we send packets 1, 2, 3, 4, 5, but packet 2 was lost and every other packets were received. Then the receiver would send the same ACK for packets 3 $\approx$ 5
	\item \textit{If sender receives 3 duplicate ACKs (except for the first normal ACK) with same data, the sender will re-send the unacknowledged segment with the smallest sequence number}
	\item TCP re-transmissions are triggered by: timeout events and duplicated ACKs 
\end{itemize}

\subsubsection{TCP Flow Control}
\begin{itemize}
	\item The receiver controls the sender, so that the sender won't overflow receiver's buffer by transmitting too much data too fast. This is called \textbf{flow control}
	\item The remaining size of the receiver's buffer will be transmitted in the \textbf{receive window} field in the TCP header
	\item The sender will limit the size of transmission to the value inside the \textit{receive window} field
\end{itemize}

\subsubsection{Connection Management}
\begin{itemize}
	\item 9 flags in the TCP header - 3 are not almost never used
	\item Remaining 6: URG(\textit{urgent}), ACK(\textit{acknowledge}), PSH(\textit{push}), RST(\textit{reset}), SYN(\textit{synchronize}), FIN(\textit{finale})
	\item URG, PSH are also not used frequently
	\item \textbf{RST, SYN, FIN} flags contribute to TCP connection management
\end{itemize}

\paragraph{Three Way Handshake}
\begin{enumerate}
	\item The client requests for a connection and sends a segment with SYN flag set, and a sequence number $x$ to start with
	\item The server will receive the segment and respond with ACK flag set, and ACK number will be $x+1$. Moreover, since TCP is \textit{full duplex}, the segment will have SYN flag set and the sequence number will be $y$
	\item The client responds with ACK flag set and ACK number $y+1$
\end{enumerate}

\paragraph{Closing Connection}
\begin{enumerate}
	\item The client will send a segment with FIN flag set
	\item The server will respond with ACK flag set
	\item Connection from client to server is closed\footnote{Note that at this point, the connection from the server to the client still lives. The server can still send data.}
	\item The server will send a segment with FIN flag set
	\item The client will respond with ACK flag set
	\item Connection from server to client is closed
\end{enumerate}

\paragraph{RST Flag}
\begin{itemize}
	\item The client will ask for a port in the server to connect with
	\item If there are no processes listening to that port, the server will respond with a segment with RST flag set
	\item Used as a flag to reset the connection 
\end{itemize}


\subsection{Congestion Control}
\subsubsection{Network Congestion}
\begin{itemize}
	\item Congestion was not an issue before the 1970s, when the Internet was first developed. There weren't many nodes, and there wasn't much traffic
	\item \textbf{Congestion collapse}
	\begin{itemize}
		\item When the offered load is smaller than the network capacity, the traffic is transmitted to the destination. (offered load $\approx$ effective load)
		\item But as the offered load increases and exceeds the network capacity, the effective load decreases and eventually goes to 0.\footnote{Network will have more data to process, then the delay for each packet will increase, causing timeouts a lot more often, and causes re-transmission. Eventually, the effective load will decrease.}
	\end{itemize}
	\item \textbf{Congestion}: Too many sources sending too much data too fast for the network to handle
	\item Difference between \textit{flow control}
	\begin{itemize}
		\item Flow control is a point-to-point issue, between a sender and a receiver
		\item Flow control problem could be resolved only by knowing the receiver buffer size, which is in the receiver window field in the TCP header
		\item Congestion control is a \textit{global} issue
		\item All the nodes that share the whole network have to yield to each other - only then the traffic will decrease
	\end{itemize}
	\item Manifestations: lost packets (buffer overflow at routers), long delays (queueing in router buffers)
\end{itemize}

\subsubsection{Congestion Control Approaches}
\paragraph{Network Assisted}
\begin{itemize}
	\item Data from multiple sources go through routers
	\item The routers \textit{notify} the end systems, and provide feedback that congestion is happening, and also provides the explicit rate for the sender to send data at
	\item Single bit indicating congestion (SNA, DECbit, TCP/IP\footnote{There is a flag in the TCP header for \textit{explicited congestion notification}. But this is rarely used.}, ECN, ATM)
	\item But this is quite complicated and causes problems - TCP uses end-to-end
\end{itemize}

\paragraph{End to End}
\begin{itemize}
	\item No explicit feedback from the network 
	\item Congestion is inferred from the observed loss and delay by the end system
	\item Approach taken by TCP
\end{itemize}

\subsubsection{TCP Congestion Control Overview}
\begin{itemize}
	\item \textbf{AIMD} approach: sender increases transmission rate (window size), probing for usable bandwidth, until loss occurs
	\begin{itemize}
		\item \textit{Additive increase}: increase \texttt{cwnd} by 1 MSS\footnote{Maximum segment size} every RTT until loss is detected
		\item \textit{Multiplicative decrease}: Cut \texttt{cwnd} in half after loss
	\end{itemize}
	\item \textbf{Congestion window} (\texttt{cwnd}): Maximum amount of un-ACKed packets in transit, without causing congestion
	\item (Size of data between \textit{last byte sent} and \textit{last byte ACKed}) $\leq$ $\min$(\texttt{cwnd}, \texttt{rwnd})\\
	\texttt{rwnd}: Receive window (receiver buffer)
	\item \texttt{cwnd} is dynamic, changes with respect to network congestion
	\item How do you decide the size of \texttt{cwnd} when connection has just began?
\end{itemize}

\paragraph{Slow Start}
\begin{itemize}
	\item When connection begins, increase rate exponentially, until the first loss event occurs
	\begin{itemize}
		\item Initially set \texttt{cwnd} as 1 MSS
		\item Double \texttt{cwnd} every RTT, if the sent packet is ACKed
	\end{itemize}
	\item Note that the \textit{initial rate} is slow, but the size increases exponentially fast
	\item When should this increase stop?
\end{itemize}

\paragraph{Congestion Avoidance}
\begin{itemize}
	\item If all nodes increase its \texttt{cwnd} exponentially, this would cause congestion very fast
	\item A variable \texttt{ssthresh} (slow start threshold) is used
	\item On a loss event, \texttt{ssthresh} is set to half of [\texttt{cwnd} value of the most recent successful transfer]\footnote{\texttt{ssthresh} starts at some value (may be high) when the end system connects to the network for the first time. As time passes and the system transmits data through the network, this \texttt{ssthresh} value will be maintained}
	\item If the \texttt{cwnd} size exceeds \texttt{ssthresh}, \texttt{cwnd} increases by a single MSS every RTT
	\item Exponential increase if less than \texttt{ssthresh}, linear increase after exceeding \texttt{ssthresh}
\end{itemize}

\subsection{TCP Congestion Control Algorithm}
\begin{itemize}
	\item The following TCP variants were or (currently) is the standard
\end{itemize}

\subsubsection{TCP Tahoe (1988)}
\begin{itemize}
	\item Slow start, congestion avoidance
	\item When loss is detected, set \texttt{cwnd} to 1
	\item \textbf{Fast re-transmit}: re-transmission upon 3 duplicate ACKs 
	\item Slow start begins on timeout and fast re-transmit
\end{itemize}

\subsubsection{TCP Reno (1990)}
\begin{itemize}
	\item Limitations of Tahoe
	\begin{itemize}
		\item Doesn't differentiate between losses indicated by timeout and duplicate ACKs
		\item Always sets \texttt{cwnd} to 1 MSS (throughput decrease)
	\end{itemize}
	\item Two (different) responses to packet losses by Reno
	\item Loss indicated by \textit{timeout}
	\begin{itemize}
		\item Set \texttt{cwnd} to 1 MSS
		\item \textit{Slow start} to \texttt{ssthresh}, then congestion avoidance begins
	\end{itemize}
	\item Loss indicated by \textit{fast re-transmit}
	\begin{itemize}
		\item \texttt{cwnd} is cut in half
		\item \textbf{Fast recovery}, then congestion avoidance
	\end{itemize}
\end{itemize}

\paragraph{Fast Recovery}
\begin{itemize}
	\item Half of \texttt{cwnd} size is maintained until a non-duplicate ACK is received
	\item Amount of packets in transit is kept from decreasing more than expected
	\item Operation
	\begin{enumerate}
		\item Upon the event of 3 duplicate ACKs, reduce \texttt{cwnd} to 1/2
		\item Re-transmit the oldest un-ACKed packet
		\item Inflate the congestion window by the number of duplicated packets
		\item A non-duplicate ACK starts congestion avoidance
	\end{enumerate}
\end{itemize}

\subsubsection{TCP NewReno (1999)}
\begin{itemize}
	\item Vulnerability of Reno's fast recovery - in case of multiple packet losses\footnote{And usually, multiple packets are lost, not just single one}, \texttt{cwnd} may be reduced too much (exponential way)
	\item Reno stops fast recovery on non-duplicated ACK
	\item But NewReno restricts the exit from recovery until all data packets from the initial congestion window are ACKed (resistant to multiple packet losses)
	\item Exits from fast recovery only when a new data ACK is received
	\item Keeps the sequence number of the last data packet sent before entering fast recovery	
\end{itemize}

\subsubsection{TCP SACK (1996)}
\begin{itemize}
	\item Limited information of cumulative ACKs
	\begin{itemize}
		\item ACK of only the last in-order packet
		\item Reno's fast recovery assumes loss of only 1 data packet
		\item A duration of the recovery is directly proportional to the number of packet losses
	\end{itemize}
	\item \textbf{SACK} (Selective ACK): receiver provides information about several packet losses in a single ACK message by reporting blocks of successfully delivered data packets
	\item Client sends packets 1, 2, 3, 4 and if packet 2 is lost, ACK message from the server will contain: ACK for packet 1, SACK for 3, 4
	\item Then the client only has to re-transmit packet 2
\end{itemize}

\subsection{TCP vs UDP}
\begin{itemize}
	\item Fairness between connections
	\begin{itemize}
		\item TCP has AIMD - difference of throughput between connections is reduced by half, when loss occurs, and eventually the difference tends to 0 (fairness)
		\item UDP sends the amount the sender wants to send (unfair)
		\item Note that multimedia applications do not want the rate throttled by congestion control, so they use UDP and tolerate packet loss
	\end{itemize}
\end{itemize}

\begin{center}
	\begin{tabular}{l|l}
		\textbf{TCP} & \textbf{UDP} \\\hline
		 - Slower but reliable transfers & - Fast but non-guaranteed transfers \\
		 - Email, web browsing & - VoIP, music streaming\\
		 - Unicast & - Unicast, multicast, broadcast
	\end{tabular}
\end{center}

\pagebreak
